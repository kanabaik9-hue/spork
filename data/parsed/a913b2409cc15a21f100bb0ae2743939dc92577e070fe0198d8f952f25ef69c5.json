{"url": "https://spacy.io/", "title": "spaCy \u00b7 Industrial-strength Natural Language Processing in Python", "headings": ["spaCy", "Industrial-StrengthNatural LanguageProcessing", "in Python", "Get things done ", "Blazing fast ", "Awesome ecosystem ", "Features ", "NEWLarge Language Models: Integrating LLMs into structured NLP pipelines ", "From the makers of spaCyProdigy: Radically efficient machine teaching ", "Reproducible training for custom pipelines ", "End-to-end workflows from prototype to production ", "Benchmarks "], "body": "spaCy is designed to help you do real work \u2014 to build real products, or gather real insights. The library respects your time, and tries to avoid wasting it. It's easy to install, and its API is simple and productive. spaCy excels at large-scale information extraction tasks. It's written from the ground up in carefully memory-managed Cython. If your application needs to process entire web dumps, spaCy is the library you want to be using. Since its release in 2015, spaCy has become an industry standard with a huge ecosystem. Choose from a variety of plugins, integrate with your machine learning stack and build custom components and workflows. The spacy-llm package integrates Large Language Models (LLMs) into spaCy, featuring a modular system for fast prototyping and prompting, and turning unstructured responses into robust outputs for various NLP tasks, no training data required.  Prodigy is an annotation tool so efficient that data scientists can do the annotation themselves, enabling a new level of rapid iteration. Whether you're working on entity recognition, intent detection or image classification, Prodigy can help you train and evaluate your models faster. spaCy v3.0 introduces a comprehensive and extensible system for configuring your training runs. Your configuration file will describe every detail of your training run, with no hidden defaults, making it easy to rerun your experiments and track changes. You can use the quickstart widget or the init config command to get started, or clone a project template for an end-to-end workflow. Get started spaCy's new project system gives you a smooth path from prototype to production. It lets you keep track of all those data transformation, preprocessing and training steps, so you can make sure your project is always ready to hand over for automation. It features source asset download, command execution, checksum verification, and caching with a variety of backends and integrations. Try it out  Get a custom spaCy pipeline, tailor-made for your NLP problem by spaCy's core developers.  In this free and interactive online course you\u2019ll learn how to use spaCy to build advanced natural language understanding systems, using both rule-based and machine learning approaches. It includes 55 exercises featuring videos, slide decks, multiple-choice questions and interactive coding practice in the browser. spaCy v3.0 introduces transformer-based pipelines that bring spaCy's accuracy right up to the current state-of-the-art. You can also use a CPU-optimized pipeline, which is less accurate but much cheaper to run. More results Full pipeline accuracy on the\nOntoNotes 5.0 corpus (reported on\nthe development set). Named entity recognition accuracy on the\nOntoNotes 5.0 and\nCoNLL-2003 corpora. See\nNLP-progress for\nmore results. Project template:\nbenchmarks/ner_conll03. 1.\nQi et al. (2020). 2.\nAkbik et al. (2018).", "tokens": ["spacy", "design", "help", "real", "work", "build", "real", "product", "gather", "real", "insight", "library", "respect", "time", "try", "avoid", "waste", "easy", "install", "api", "simple", "productive", "spacy", "excel", "large", "scale", "information", "extraction", "task", "write", "ground", "carefully", "memory", "manage", "cython", "application", "need", "process", "entire", "web", "dump", "spacy", "library", "want", "use", "release", "spacy", "industry", "standard", "huge", "ecosystem", "choose", "variety", "plugin", "integrate", "machine", "learn", "stack", "build", "custom", "component", "workflow", "spacy", "llm", "package", "integrate", "large", "language", "models", "llms", "spacy", "feature", "modular", "system", "fast", "prototype", "prompt", "turn", "unstructured", "response", "robust", "output", "nlp", "task", "training", "datum", "require", "prodigy", "annotation", "tool", "efficient", "datum", "scientist", "annotation", "enable", "new", "level", "rapid", "iteration", "work", "entity", "recognition", "intent", "detection", "image", "classification", "prodigy", "help", "train", "evaluate", "model", "fast", "spacy", "introduce", "comprehensive", "extensible", "system", "configure", "training", "run", "configuration", "file", "describe", "detail", "training", "run", "hidden", "default", "easy", "rerun", "experiment", "track", "change", "use", "quickstart", "widget", "init", "config", "command", "start", "clone", "project", "template", "end", "end", "workflow", "start", "spacy", "new", "project", "system", "smooth", "path", "prototype", "production", "let", "track", "datum", "transformation", "preprocessing", "training", "step", "sure", "project", "ready", "hand", "automation", "feature", "source", "asset", "download", "command", "execution", "checksum", "verification", "cache", "variety", "backend", "integration", "try", "custom", "spacy", "pipeline", "tailor", "nlp", "problem", "spacy", "core", "developer", "free", "interactive", "online", "course", "learn", "use", "spacy", "build", "advanced", "natural", "language", "understanding", "system", "use", "rule", "base", "machine", "learning", "approach", "include", "exercise", "feature", "video", "slide", "deck", "multiple", "choice", "question", "interactive", "code", "practice", "browser", "spacy", "introduce", "transformer", "base", "pipeline", "bring", "spacy", "accuracy", "right", "current", "state", "art", "use", "cpu", "optimize", "pipeline", "accurate", "cheap", "run", "result", "pipeline", "accuracy", "ontonotes", "corpus", "report", "development", "set", "entity", "recognition", "accuracy", "ontonotes", "corpora", "nlp", "progress", "result", "project", "template", "benchmark", "qi", "et", "al", "akbik", "et", "al"], "metadata": {"url": "https://spacy.io/", "title": "spaCy \u00b7 Industrial-strength Natural Language Processing in Python", "headings": ["spaCy", "Industrial-StrengthNatural LanguageProcessing", "in Python", "Get things done ", "Blazing fast ", "Awesome ecosystem ", "Features ", "NEWLarge Language Models: Integrating LLMs into structured NLP pipelines ", "From the makers of spaCyProdigy: Radically efficient machine teaching ", "Reproducible training for custom pipelines ", "End-to-end workflows from prototype to production ", "Benchmarks "], "content_length": 2892, "lang": "en", "canonical_url": "https://spacy.io/", "outbound_links": ["/", "https://github.com/explosion/spacy-layout", "/usage", "/models", "/api", "/universe", "https://github.com/explosion/spaCy", "/usage/spacy-101", "/usage/facts-figures", "/usage/projects", "https://mybinder.org/", "/usage/large-language-models", "https://github.com/explosion/spacy-llm", "/usage/large-language-models", "https://prodi.gy", "https://prodi.gy", "https://prodi.gy", "/api/cli#init-config", "/usage/training", "data:application/octet-stream,%23%20This%20is%20an%20auto-generated%20partial%20config.%20To%20use%20it%20with%20'spacy%20train'%0A%23%20you%20can%20run%20spacy%20init%20fill-config%20to%20auto-fill%20all%20default%20settings%3A%0A%23%20python%20-m%20spacy%20init%20fill-config%20.%2Fbase_config.cfg%20.%2Fconfig.cfg%0A%5Bpaths%5D%0Atrain%20%3D%20null%0Adev%20%3D%20null%0Avectors%20%3D%20null%0A%5Bsystem%5D%0Agpu_allocator%20%3D%20null%0A%0A%5Bnlp%5D%0Alang%20%3D%20%22en%22%0Apipeline%20%3D%20%5B%5D%0Abatch_size%20%3D%201000%0A%0A%5Bcomponents%5D%0A%0A%5Bcorpora%5D%0A%0A%5Bcorpora.train%5D%0A%40readers%20%3D%20%22spacy.Corpus.v1%22%0Apath%20%3D%20%24%7Bpaths.train%7D%0Amax_length%20%3D%200%0A%0A%5Bcorpora.dev%5D%0A%40readers%20%3D%20%22spacy.Corpus.v1%22%0Apath%20%3D%20%24%7Bpaths.dev%7D%0Amax_length%20%3D%200%0A%0A%5Btraining%5D%0Adev_corpus%20%3D%20%22corpora.dev%22%0Atrain_corpus%20%3D%20%22corpora.train%22%0A%0A%5Btraining.optimizer%5D%0A%40optimizers%20%3D%20%22Adam.v1%22%0A%0A%5Btraining.batcher%5D%0A%40batchers%20%3D%20%22spacy.batch_by_words.v1%22%0Adiscard_oversize%20%3D%20false%0Atolerance%20%3D%200.2%0A%0A%5Btraining.batcher.size%5D%0A%40schedules%20%3D%20%22compounding.v1%22%0Astart%20%3D%20100%0Astop%20%3D%201000%0Acompound%20%3D%201.001%0A%0A%5Binitialize%5D%0Avectors%20%3D%20%24%7Bpaths.vectors%7D", "/usage/projects", "https://github.com/explosion/projects/tree/v3/pipelines/tagger_parser_ud", "/usage/projects", "https://explosion.ai/custom-solutions", "https://explosion.ai/custom-solutions", "https://course.spacy.io", "https://course.spacy.io", "/usage/facts-figures#benchmarks", "/models/en#en_core_web_trf", "/models/en#en_core_web_lg", "https://catalog.ldc.upenn.edu/LDC2013T19", "https://catalog.ldc.upenn.edu/LDC2013T19", "https://www.aclweb.org/anthology/W03-0419.pdf", "http://nlpprogress.com/english/named_entity_recognition.html", "https://github.com/explosion/projects/tree/v3/benchmarks/ner_conll03", "https://arxiv.org/pdf/2003.07082.pdf", "https://www.aclweb.org/anthology/C18-1139/", "/usage", "/models", "/api", "https://course.spacy.io", "https://explosion.ai/custom-solutions", "/universe", "https://github.com/explosion/spaCy/discussions", "https://github.com/explosion/spaCy/issues", "http://stackoverflow.com/questions/tagged/spacy", "https://explosion.ai/merch", "https://bsky.app/profile/explosion-ai.bsky.social", "https://github.com/explosion/spaCy", "https://www.youtube.com/playlist?list=PLBmcuObd5An5_iAxNYLJa_xWmNzsYce8c", "https://youtube.com/c/ExplosionAI", "https://explosion.ai/blog", "https://explosion.ai", "https://explosion.ai", "https://explosion.ai/legal"]}}